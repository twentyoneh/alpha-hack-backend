services:
  db:
    image: postgres:16-alpine
    container_name: request-postgres
    environment:
      POSTGRES_DB: requestdb
      POSTGRES_USER: request
      POSTGRES_PASSWORD: request
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U request -d requestdb"]
      interval: 5s
      timeout: 3s
      retries: 10
    restart: unless-stopped

  app:
    build: .
    container_name: request-service
    depends_on:
      db:
        condition: service_healthy
      localai:
        condition: service_healthy
    environment:
      SPRING_PROFILES_ACTIVE: docker
      DB_HOST: db
      DB_PORT: "5432"
      DB_NAME: requestdb
      DB_USER: request
      DB_PASSWORD: request
      LOCALAI_BASE_URL: http://localai:8080
    ports:
      - "8081:8081"
    restart: unless-stopped

  localai:
    image: localai/localai:latest
    container_name: local-ai-service
    ports:
      - "8080:8080"
    command: ["run", "llama-3.2-1b-instruct:q4_k_m"]
    volumes:
      - localai_models:/models
    healthcheck:
      test: ["CMD-SHELL", "wget --quiet --tries=1 --spider http://localhost:8080/v1/models && wget --quiet --tries=1 -O- http://localhost:8080/v1/models | grep -q 'llama-3.2-1b-instruct' || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 120s
    restart: unless-stopped

volumes:
  pgdata:
  localai_models: